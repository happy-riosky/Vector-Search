{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a94f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ollama åœ¨ Python ä¸­çš„ä½¿ç”¨æŒ‡å—ï¼ˆä¸­æ–‡ï¼‰\n",
      "\n",
      "Ollama æ˜¯ä¸€æ¬¾è½»é‡çº§çš„æœ¬åœ° LLM æœåŠ¡ç«¯ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ï¼ˆå¦‚ Llamaâ€‘3ã€Mistralã€Gemma ç­‰ï¼‰ã€‚  \n",
      "å®ƒæä¾›äº† **Python SDK**ï¼ˆ`ollama` åŒ…ï¼‰ï¼Œå¯ä»¥åƒè°ƒç”¨ OpenAI æ¥å£ä¸€æ ·ï¼Œåœ¨æœ¬åœ°è°ƒç”¨æ¨¡å‹ã€‚  \n",
      "ä¸‹é¢æŒ‰æ­¥éª¤è¯´æ˜å¦‚ä½•åœ¨ Python é¡¹ç›®é‡Œä½¿ç”¨ Ollamaã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 1. ç¯å¢ƒå‡†å¤‡\n",
      "\n",
      "| æ­¥éª¤ | å‘½ä»¤ | è¯´æ˜ |\n",
      "|------|------|------|\n",
      "| 1. å®‰è£… Ollama CLI | `curl -fsSL https://ollama.com/install.sh | sh` æˆ–è€… Windows PowerShell `<script>` | ä¸‹è½½å¹¶å®‰è£…æœ¬åœ°æœåŠ¡å™¨ã€‚ |\n",
      "| 2. æ‹‰å–æ¨¡å‹ | `ollama pull llama3` | ä½ å¯ä»¥æŠŠ `llama3` æ¢æˆä½ æƒ³ç”¨çš„æ¨¡å‹åã€‚ |\n",
      "| 3. å¯åŠ¨æœåŠ¡å™¨ | `ollama serve` | æœåŠ¡å™¨é»˜è®¤ç›‘å¬ `http://localhost:11434`ã€‚ |\n",
      "\n",
      "> **æç¤º**ï¼šå¦‚æœä½ åªæƒ³åœ¨è„šæœ¬é‡Œä½¿ç”¨ SDKï¼Œå¯ä»¥çœç•¥æ‰‹åŠ¨å¯åŠ¨ï¼ŒSDK ä¼šè‡ªåŠ¨å°è¯•è¿æ¥æœ¬åœ°æœåŠ¡å™¨ï¼ˆéœ€è¦å…ˆåœ¨åå°è¿è¡Œ `ollama serve`ï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 2. å®‰è£… Python SDK\n",
      "\n",
      "```bash\n",
      "pip install ollama\n",
      "```\n",
      "\n",
      "> ç‰ˆæœ¬ä¿¡æ¯ï¼šæˆªè‡³ 2025â€‘08â€‘17ï¼Œæœ€æ–° SDK ç‰ˆæœ¬ä¸º `ollama==0.3.0`ï¼ˆå®é™…è¯·æŸ¥çœ‹ PyPIï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 3. åŸºæœ¬ä½¿ç”¨\n",
      "\n",
      "#### 3.1 è¿æ¥åˆ°æœ¬åœ° Ollama æœåŠ¡å™¨\n",
      "\n",
      "```python\n",
      "import ollama\n",
      "\n",
      "# ç›´æ¥ä½¿ç”¨é»˜è®¤æœ¬åœ°åœ°å€\n",
      "client = ollama.Client(host=\"http://localhost:11434\")\n",
      "```\n",
      "\n",
      "> `Client` çš„æ„é€ å‡½æ•°æ”¯æŒ `host`ã€`timeout` ç­‰å‚æ•°ï¼Œé»˜è®¤ `host=\"http://localhost:11434\"`ã€‚\n",
      "\n",
      "#### 3.2 åˆ—å‡ºå·²æ‹‰å–çš„æ¨¡å‹\n",
      "\n",
      "```python\n",
      "models = client.list()\n",
      "print(models)\n",
      "# [{'name': 'llama3', 'modified_at': '2025-08-17T12:34:56+00:00'}, ...]\n",
      "```\n",
      "\n",
      "#### 3.3 æ–‡æœ¬ç”Ÿæˆï¼ˆCompletionï¼‰\n",
      "\n",
      "```python\n",
      "prompt = \"è¯·ç”¨ä¸‰å¥è¯ä»‹ç»ä¸€ä¸‹ Ollamaã€‚\"\n",
      "\n",
      "resp = client.generate(\n",
      "    model=\"llama3\",\n",
      "    prompt=prompt,\n",
      "    temperature=0.7,      # 0.0-1.0\n",
      "    top_p=0.9,            # 0.0-1.0\n",
      "    stream=False          # æ˜¯å¦æµå¼è¿”å›\n",
      ")\n",
      "\n",
      "print(resp[\"response\"])\n",
      "```\n",
      "\n",
      "> **è¿”å›æ ¼å¼**ï¼š`{'model': 'llama3', 'response': 'â€¦', 'created_at': 'â€¦'}`\n",
      "\n",
      "#### 3.4 èŠå¤©å¼ç”Ÿæˆï¼ˆChatï¼‰\n",
      "\n",
      "```python\n",
      "messages = [\n",
      "    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€åå¸®åŠ©ç”¨æˆ·çš„æŠ€æœ¯æ”¯æŒåŠ©æ‰‹ã€‚\"},\n",
      "    {\"role\": \"user\", \"content\": \"å¦‚ä½•åœ¨ Python ä¸­ä½¿ç”¨ Ollamaï¼Ÿ\"},\n",
      "]\n",
      "\n",
      "resp = client.chat(\n",
      "    model=\"llama3\",\n",
      "    messages=messages,\n",
      "    temperature=0.6,\n",
      "    stream=False\n",
      ")\n",
      "\n",
      "print(resp[\"message\"][\"content\"])\n",
      "```\n",
      "\n",
      "> ä¸ OpenAI Chat API çš„è°ƒç”¨æ–¹å¼å®Œå…¨ç›¸åŒã€‚\n",
      "\n",
      "#### 3.5 è·å–å‘é‡ï¼ˆEmbeddingï¼‰\n",
      "\n",
      "```python\n",
      "text = \"Ollama æ˜¯ä¸€ä¸ªæœ¬åœ° LLM æœåŠ¡ã€‚\"\n",
      "emb = client.embeddings(\n",
      "    model=\"llama3\",\n",
      "    input=text\n",
      ")\n",
      "print(emb[\"embedding\"])  # ç»´åº¦ä¸º 4096ï¼ˆæˆ–æ ¹æ®æ¨¡å‹è€Œå®šï¼‰\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 4. è¿›é˜¶ï¼šæµå¼ï¼ˆStreamingï¼‰è°ƒç”¨\n",
      "\n",
      "æµå¼å¯ä»¥è¾¹ç”Ÿæˆè¾¹å¤„ç†æ–‡æœ¬ï¼Œé€‚åˆèŠå¤© UIã€‚\n",
      "\n",
      "```python\n",
      "for token in client.generate(\n",
      "        model=\"llama3\",\n",
      "        prompt=\"å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—\",\n",
      "        stream=True):\n",
      "    # token æ˜¯å­—å…¸ï¼Œ{'content': 'â€¦'}\n",
      "    print(token[\"content\"], end=\"\", flush=True)\n",
      "print()\n",
      "```\n",
      "\n",
      "> ä½ å¯ä»¥æŠŠå®ƒåŒ…è£…æˆå¼‚æ­¥ç”Ÿæˆå™¨ï¼Œé…åˆ `asyncio` è¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 5. é”™è¯¯å¤„ç†\n",
      "\n",
      "```python\n",
      "try:\n",
      "    client.generate(...)\n",
      "except ollama.exceptions.APIError as e:\n",
      "    print(f\"Ollama API error: {e}\")\n",
      "except ollama.exceptions.ConnectionError:\n",
      "    print(\"æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡å™¨ï¼Œè¯·å…ˆæ‰§è¡Œ `ollama serve`ã€‚\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 6. åœ¨ Docker / CI ç¯å¢ƒä¸­ä½¿ç”¨\n",
      "\n",
      "å¦‚æœä½ åœ¨ Docker å®¹å™¨æˆ– CI ç¯å¢ƒé‡Œéƒ¨ç½²ï¼Œæ¨èä½¿ç”¨ `ollama serve` å¹¶åœ¨åå°ä¿æŒè¿è¡Œï¼š\n",
      "\n",
      "```dockerfile\n",
      "FROM python:3.12-slim\n",
      "\n",
      "RUN pip install ollama\n",
      "COPY ./your_script.py /app/\n",
      "\n",
      "CMD [\"sh\", \"-c\", \"ollama serve & python /app/your_script.py\"]\n",
      "```\n",
      "\n",
      "> `ollama serve &` è®©æœåŠ¡å™¨åœ¨åå°å¯åŠ¨ï¼Œè„šæœ¬å³å¯ç«‹å³è¿æ¥ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 7. å¸¸è§é—®é¢˜\n",
      "\n",
      "| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |\n",
      "|------|----------|\n",
      "| **Ollama æœåŠ¡å™¨å¯åŠ¨åæŠ¥ `OSError: [Errno 98] Address already in use`** | æ£€æŸ¥ç«¯å£ 11434 æ˜¯å¦è¢«å ç”¨ï¼Œæˆ–æ”¹ç”¨ `ollama serve --port 11435`ã€‚ |\n",
      "| **æ¨¡å‹æ‹‰å–å¤±è´¥ï¼Œç½‘ç»œæ…¢** | ä½¿ç”¨ `--timeout` æˆ–é…ç½®ä»£ç†ï¼š`export http_proxy=http://...`ã€‚ |\n",
      "| **Python ä»£ç æŠ¥ `ModuleNotFoundError: No module named 'ollama'`** | ç¡®è®¤å·²åœ¨åŒä¸€ç¯å¢ƒä¸‹å®‰è£… `pip install ollama`ï¼Œå¹¶æ¿€æ´»ç›¸åº”çš„è™šæ‹Ÿç¯å¢ƒã€‚ |\n",
      "| **ç”Ÿæˆæ–‡æœ¬å¤ªé•¿** | åœ¨è°ƒç”¨æ—¶é™åˆ¶ `max_tokens`ï¼ˆå¦‚æœ SDK æ”¯æŒï¼‰æˆ–è‡ªè¡Œæˆªæ–­ã€‚ |\n",
      "\n",
      "---\n",
      "\n",
      "### 8. å°ç»“\n",
      "\n",
      "1. **å®‰è£…** Ollama CLI â†’ æ‹‰å–æ¨¡å‹ â†’ å¯åŠ¨æœåŠ¡å™¨ã€‚  \n",
      "2. **å®‰è£…** `ollama` Python SDKã€‚  \n",
      "3. **ä½¿ç”¨** `Client` è¿›è¡Œ `generate` / `chat` / `embeddings` ç­‰è°ƒç”¨ï¼Œæ”¯æŒåŒæ­¥/æµå¼ã€‚  \n",
      "4. **é”™è¯¯å¤„ç†** ä¸ `try/except`ï¼Œå¹¶ä¿æŒæœåŠ¡å™¨æ­£å¸¸è¿è¡Œã€‚  \n",
      "\n",
      "è¿™æ ·ï¼Œä½ å°±å¯ä»¥åœ¨æœ¬åœ°ã€å®Œå…¨ç¦»çº¿çš„ç¯å¢ƒé‡Œï¼Œåƒè°ƒç”¨ OpenAI API ä¸€æ ·ï¼Œç”¨ Python è°ƒç”¨ Ollama è¿›è¡Œå¤§æ¨¡å‹æ¨ç†ã€‚ç¥ä½ ç©å¾—æ„‰å¿« ğŸš€ï¼\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ–‡æœ¬\n",
    "response = ollama.chat(\n",
    "    model='gpt-oss:20b',  # æ›¿æ¢ä¸ºä½ å·²æ‹‰å–çš„æ¨¡å‹åç§°\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡è§£é‡Šå¦‚ä½•åœ¨ Python ä¸­ä½¿ç”¨ Ollamaã€‚'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# è¾“å‡ºæ¨¡å‹çš„å“åº”\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62082607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**æ—¥è¯­ç¿»è¯‘**  \n",
      "ã‚ãªãŸã¯é¦¬é¹¿ã§ã™ã‹ï¼Ÿ  \n",
      "\n",
      "**ç½—é©¬éŸ³ï¼ˆRomajiï¼‰**  \n",
      "Anata wa baka desu ka?\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='gpt-oss:20b',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'ç”¨æ—¥è¯­ç¿»è¯‘å¹¶æ ‡æ³¨ç½—é©¬éŸ³: ä½ æ˜¯ä¸æ˜¯å‚»? '},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcbbee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "examgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
